\documentclass[11pt,twocolumn,nocopyright]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

% save and then undefine the conflicting command
% we need \makeatletter because \@undefined uses the special @ character.

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{hyperref}
\usepackage{alltt}
\usepackage{listings}
\usepackage{array}
\usepackage{extarrows}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usetikzlibrary{calc}
\usetikzlibrary{positioning}
\usepackage{floatrow}
\usepackage[noline, boxed, procnumbered, linesnumberedhidden, titlenumbered]{algorithm2e} 

%\usepackage[margin=0.75in]{geometry}

%\usepackage{graphviz}
%\usepackage{gastex}

\newcommand{\cut}[1]{}

\newcommand{\sbull}{\,\begin{picture}(-1,1)(-1,-2.2)\circle*{2.2}\end{picture}\ }

\newcommand{\techreport}[1]{} % drop #1 to make it a cut
\newcommand{\todo}[1]{{\bf\em TODO:} #1}
\newcommand{\rem}[1]{{\bf\em rem:} #1}
\newcommand{\reminder}[1]{{\it #1 }}
\newcommand{\edcom}[1]{\textbf{{#1}}}
%\newcommand{\poplversion}[1]{#1}
\newcommand{\trversion}[1]{}

\newcommand{\appref}[1]{Appendix~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\tblref}[1]{Table~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\thmref}[1]{Theorem~\ref{#1}}
\newcommand{\algref}[1]{Algorithm~\ref{#1}}
\newcommand{\funref}[1]{Function~\ref{#1}}
\newcommand{\listingref}[1]{Listing~\ref{#1}}
%\newcommand{\pref}[1]{{page~\pageref{#1}}}

\newcommand{\eg}{{\em e.g.}}
\newcommand{\cf}{{\em cf.}}
\newcommand{\ie}{{\em i.e.}}
\newcommand{\etal}{{\em et al}}
\newcommand{\etc}{{\em etc.\/}}
\newcommand{\naive}{na\"{\i}ve}
\newcommand{\role}{r\^{o}le}
\newcommand{\forte}{{fort\'{e}\/}}
\newcommand{\appr}{\~{}}

\newcommand{\llk}{{\em LL(k)}}
\newcommand{\lalrk}{{\em LALR(k)}}
\newcommand{\lalr}{{\em LALR}}
\newcommand{\LL}{{\em LL}}
\newcommand{\LR}{{\em LR}}
\newcommand{\lrk}{{\em LR(k)}}
\newcommand{\lr}{{\em LR}}
\newcommand{\llr}{{\em LL}-regular}
\newcommand{\lrr}{{\em LR}-regular}
\newcommand{\sllr}{{\em SLL}-regular}
\newcommand{\SLL}{{\em SLL}}
\newcommand{\slls}{{\em SLL(*)}}
\newcommand{\lls}{{\em LL(*)}}
\newcommand{\alls}{{\em ALL(*)}}
\newcommand{\salls}{{\em SALL(*)}}
\newcommand{\smallstate}[1]{\vspace{.4em}\mbox{\Large $\bigcirc \hspace{-0.47cm}$} \raisebox{.02em}{$#1$} }
\newcommand{\bigstate}[1]{\vspace{.4em}{\huge $\bigcirc \hspace{-0.67cm}$} \raisebox{.3em}{$#1$} }
\newcommand{\state}[1]{\bigstate{~#1~}}
\newcommand{\gpos}{\raisebox{.2em}{\,.}}
\newcommand{\store}{\mathbb{S}}
\newcommand{\cont}{\mathcal{C}}
\newcommand{\ith}{$i^{th}$}

\newcommand{\closure}{\textit{closure}}
\newcommand{\move}{\textit{move}}
\newcommand{\predict}{\textit{predict}}
\newcommand{\resolve}{\textit{resolve}}
\newcommand{\resolveWithPredicate}{\textit{resolveWithPredicate}}
\newcommand{\resolvedWithPredicate}{\textit{wasResolved}}

\newcommand{\lowerbox}[2]{$_{\mbox{#2}}$}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{conjecture}{Conjecture}[section]

\newcommand{\pq}[3]{\state{#1} \hspace{-0.45em}$\xrightarrow{#2}$ \hspace{-0.8em} \state{#3}}

\toappear{}
\begin{document}

\title{Grammars: Raw lecture notes}

\authorinfo{Terence Parr\vspace{-1mm}}
           {University of San Francisco\vspace{-1mm}}
           {parrt@cs.usfca.edu}

\maketitle

\begin{abstract}
\end{abstract}

\section{Language}

A {\em language} is just the set of {\em sentences} that are valid. A sentence is a sequence of symbols or tokens (words).  At deeper level, sentences have structure in that words can't be in random order. e.g., {\em dogs like cats} vs {\em cats like dogs}.

In Western languages, we have a two level problem. First we have to break up the sequence of characters into vocabulary symbols. For example, here is a simple sentence using Morse code:

\begin{verbatim}
I like toast
..   .- .. -.- .  - --- .- ... -
I    L  I  K   E  T O   A  S   T
\end{verbatim}

The symbols or tokens represent the {\em vocabulary}. The {\em syntax} is an abstract notion describing the rules of the sentence whereas a sentence is an instance of that language. By analogy, you can think of the difference between a class definition and an instance of that class.

There are lots of ways to express syntax. Here are two obvious choices:\\

\begin{tabular}{ll}
x, xx, xxx, ...	 & delineation\\
one-or-more x's	 & english\\
\end{tabular}
~\\

This gets laborious so we tend to use more mathematical notation for compactness:\\

\begin{tabular}{ll}
$\{ x^n | n > 0\}$	&	set notation\\
{\tt x+}		&	 regular expressions (regex)\\
{\tt 'x'+}	&		ANTLR\\
\end{tabular}

It turns out we need a more sophisticated language for describing nested structures within language (such as parenthesized subexpressions).

{\bf Q}.  What is the set notation for ``one-or-more x followed by one-or-more y''? What is the set notation for ``one-or-more x followed by the same number of y''? What is the set notation for ``One x or two y''?

\section{CFGs}

A {\em grammar} is a set of rules that describe the set of valid sentences in a language, $L$. The rules have a very specific format and therefore follow a language, a {\em metalanguage}. The rules are called {\em production rules} and say how to generate strings in the language. There are rule names, {\em non-terminals}, and vocabulary symbols ({\em terminals} or {\em tokens}). The rules are of the form

$leftside \rightarrow rightside$

Context free grammar: {\em CFG} is a grammar where $leftside$ has to be a single non-terminal:

$expression \rightarrow {\bf id}$

\noindent There can be multiple rules:

\noindent $expression \rightarrow {\bf integer}$\\
$expression \rightarrow {\bf id}$

\noindent Or using the alternation operator:

$expression \rightarrow {\bf id} | {\bf integer}$

\noindent For formal grammars we tend to use single single capital letters for non-terminals in CFG notation:\\

\noindent $
E \rightarrow {\bf id} \\
E \rightarrow {\bf integer}$\\

\noindent Examples\\
 
\noindent Language $L = \{a,b\}$.\\

\noindent$
A \rightarrow {\bf a} \\
A \rightarrow {\bf b} \\
$

\noindent Or, $A \rightarrow {\bf a} | {\bf b}$\\

\noindent Infinite language: $L = \{a^*\}$:

\noindent $
A \rightarrow a A \\
A \rightarrow \epsilon \\
$

\noindent or\\

\noindent $
A \rightarrow a A \\
A \rightarrow \\
$

\noindent $L = \{a^+\}$ is described by:\\

\noindent $
A \rightarrow a A \\
A \rightarrow a\\
$

\noindent {\em draw the RTN}\\

\noindent $L = \{a^nb^n | n \ge 1\}$ is CF because we can create a context free grammar to describe it:\\

\noindent $
A \rightarrow a A b\\
A \rightarrow a b\\
$

Some languages or non-context-free, such as $L = \{a^nb^nc^n | n \ge 1\}$; there is no way to make sure all three symbols appear the same number of times.  Again, note that there is a difference between a language and its specification (the rules we use to define it). In this case, there is no context free grammar that can describe that language. Also note that there are an infinite number of grammars for describing a single language $L$.

\subsection{Formal CFG definition}

A CFG grammar $G = (N, T, P, S)$ has elements:

\vspace{-3pt}
\begin{itemize}\itemsep0pt \parskip0pt \parsep0pt
\item $N$ is the set of nonterminals (rule names)
\item $T$ is the set of terminals (tokens)
\item $P$ is the set of productions
\item $S \in N$ is the start symbol
\end{itemize}

\begin{center}\small 
\begin{tabular}{l  l}
$A  \in N$		    & Nonterminal \\
$a,b,c,d  \in T$ 	    & Terminal \\
$X  \in (N \cup T)  $ & Production element \\
$\alpha, \beta, \delta \in X^*$  & Sequence of grammar symbols\\
$u,v,w,x,y \in T^*$             & Sequence of terminals\\
%$w_r \in T^*$             & Remaining input terminals\\
$\epsilon$ & Empty string \\
$\char36$ & End of file ``symbol'' \\
\end{tabular}
\end{center}

The set of all context-free languages is identical to the set of languages accepted by pushdown automata ({\em PDA}) and all contexts we languages can be parsed in $O(n^3)$ time.  ANTLR is technically $O(n^4)$ but performs linearly $O(n)$ in practice.

\section{Regular grammars}

A regular grammar is a restricted form of a context free grammar that can describe the so-called {\em regular languages}. You can think of this as being equivalent to what basic regular expressions can describe.  You cannot describe nested structures with a regular grammar because there is no way to make the necessary recursive calls. There is no stack.

A regular grammar has a single non-terminal on the left like a CFG, but the right-hand side can only be: empty, a sequence of terminals, a sequence of terminals followed by a non-terminal, but that's it. All regular languages can be recognized by a finite state machine in linear time.  These state machines are called NFA/DFA.

Here's an example of a non-regular language: $L = \{a^nb^n | n \ge 1\}$ because we have no memory but $\{a^nb^m | n \ge 0, m \ge 0\}$ is regular. Here is the regular grammar $A \rightarrow a^* b^*$.

draw state machine
 
\section{Derivations}

How do we know what the language looks like, the set of sentence, given a grammar? Grammars can both ``generate'' and ``recognize'' input sentences (if we create a parser from the grammar). In formal languages, we tend to think of grammars as generating strings and we use special notation to describe how to derive sentences from a grammar.

A {\em derivation} is a sequence of steps that gradually transforms a grammar symbol (or grammar fragment) into a sentence (sequence of symbols). For example, given grammar $A \rightarrow a$, there is only one derivation: $A$ is transformed to $a$ using rule $A \rightarrow a$. More formally, we use a derivation operator $\Rightarrow$:

\noindent $\alpha \Rightarrow \beta$\\
$\alpha \Rightarrow^* \beta$\\
$\alpha \Rightarrow^+ \beta$

\noindent for arbitrary grammar fragments $\alpha$ and $\beta$.

To answer the question ``is a sentence in the language described by a grammar,'' we try to find a derivation from the start symbol of the grammar to that sentence. For example, consider the following grammar:

\noindent $
A \rightarrow a A b\\
A \rightarrow a b\\
$

The derivation/generation of $ab$ is $A \Rightarrow ab$. The derivation of $aabb$ is $A \Rightarrow aAb \Rightarrow aabb$. We replace symbols on the right-hand side according to the rules of the grammar. We are free to choose any alternative production for a nonterminal when replacing.

There are {\em leftmost} and {\em rightmost derivations}.\\
 
\noindent $
S \rightarrow {\bf if}\, E\, {\bf then}\, S\\
S \rightarrow {\bf return}\, E\\
E \rightarrow {\bf id}\\
$

\noindent $S \Rightarrow_{lm} {\bf if}\, E\, {\bf then}\, S \\
\Rightarrow_{lm} {\bf if}\, {\bf x}\, {\bf then}\, S \\
\Rightarrow_{lm} {\bf if}\, {\bf x}\, {\bf then}\, {\bf return}\, E \\
\Rightarrow_{lm} {\bf if}\, {\bf x}\, {\bf then}\, {\bf return}\, {\bf y}$

\noindent or

\noindent $S \Rightarrow_{rm} {\bf if}\, E\, {\bf then}\, S \\
\Rightarrow_{rm} {\bf if}\, E\, {\bf then}\, {\bf return}\, E \\
\Rightarrow_{rm} {\bf if}\, E\, {\bf then}\, {\bf return}\, {\bf y}\\
\Rightarrow_{rm} {\bf if}\, {\bf x}\, {\bf then}\, {\bf return}\, {\bf y}$

We get different derivations but we get the {\bf same tree}. Show parse tree of $A$ then if-then-else.

Formally, the language generated by grammar fragment $\alpha$ is: $L(\alpha)=\{ w \, | \, \alpha \Rightarrow^* w\}$ and the language of grammar $G$ is $L(G) = \{ w \, | \, S \Rightarrow^* w\}$. Language $L$ is CF {\em iff} there exists a CFG for $L$.

$\alpha$ is {\em sentential form} (grammar fragment) if $S$ derives to it.

Proof that $G$ gens $L$ means show every string gen'd by G is in L and every string in L can be gen'd by G.

\section{Parse trees}

A parse tree is just a record of the replacements made in a derivation. Grab the derivation by the start symbol and give it a big shake.  Show parse tree of {\tt aaa} given $A \rightarrow a A | \epsilon$.

{\bf Q}. What does parse tree look like for {\tt aab} given $A \rightarrow a A | b$.

\section{Ambiguity}

See section 5.4 in ANTLR 4 book. p69 in printed version.

``You can't put too much water in a nuclear reactor.'' 

``I once shot an elephant in my pajamas. How he got in my pajamas I will never know.'' --- Groucho Marx

If there is more than one lm or rm derivation for same input, normally it's an error in computer languages. $L$ is syntactically ambiguous in this case; e.g., expressions.  Also note that an ambiguous language $L$ gives ambig $G$.  For example, in the language C++ {\tt T(i)} is both a typecast and a function call so it is syntactically ambiguous. Expressions are the typical example used to describe ambiguous grammars:\\

\noindent $
E \rightarrow E * E\\
E \rightarrow E + E\\
E \rightarrow {\bf id}\\
$

{\tt 1+2*3} has two interpretations. The parser should recognize {\tt 1*2+3} as {\tt (1*2)+3} not {\tt 1*(2+3)}.

{\bf Q}. Show the {\bf two} leftmost derivation for {\tt 1+2*3}

One way to resolve is to convert to non-Left-recursive version: $E \rightarrow {\bf id}\ (*\ E | {\bf +}\ E)^*$.  The other way is to order the alternatives, which is what ANTLR does to show precedence.

{\bf Q}. Show the {\bf two} parse tree for {\tt 1+2*3}.

{\bf Q}. Show the parse tree for {\tt 1+2+3} using the non-left recursive grammar $E \rightarrow {\bf id}\ (*\ E | {\bf +}\ E)^*$. Now show it for {\tt 1+2*3}. Do you think it represents the precedence of the operators correctly?

{\bf Q}. Modify the expression language to allow {\bf int} integer values. 

{\bf Q}. Modify the expression language to allow nested parenthesis. 

{\bf Q}. Modify it so it allows array references.

\section{Left recursion}

Left recursion occurs when a derivation of $A$ yields another string with $A$ on the left edge: $\exists A \Rightarrow^* A\alpha$.
 
Indirectly left-recursive rules call themselves through another rule; e.g., $A \rightarrow B$, $B \rightarrow A$. Hidden left-recursion occurs
when an empty production exposes left recursion; e.g., $A \rightarrow
B A$, $B \rightarrow \epsilon$.  Here's an obvious case of direct left recursion:

\noindent $
A \rightarrow A a\\
A \rightarrow b\\
$

{\bf Q}. What sentences does this grammar generate?

\noindent Here is an indirect left recursion case:\\

\noindent $
A \rightarrow Ba\, |\, b\\
B \rightarrow A\\
$

{\bf Q}. What sentences does this grammar generate?

\noindent Here is right recursion:\\

\noindent $
A \rightarrow a A\\
A \rightarrow b\\
$

{\bf Q}. What sentences does this grammar generate?

\section{Left factoring}

\noindent $
S \rightarrow {\bf if}\, E\, {\bf then}\, S\, {\bf else}\, S\\
S \rightarrow {\bf if}\, E\, {\bf then}\, S\\
$

\noindent $
S \rightarrow {\bf if}\, E\, {\bf then}\, S\, S'\\
S' \rightarrow {\bf else}\, S \\
S' \rightarrow
$\\

\noindent or EBNF notation:\\

\noindent $
S \rightarrow {\bf if}\, E\, {\bf then}\, S\, ({\bf else}\, S)?\\
$

\section{Designing grammars}

See chapter 5 in ANTLR 4 reference guide.

\end{document}